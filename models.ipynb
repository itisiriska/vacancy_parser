{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import balanced_accuracy_score, classification_report, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'data/dataset8.pkl'\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Загрузка данных"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "        id                          responsibilities_bigrams  class\n0  9495846             (работа, на, строительных, площадках)    2.0\n1  9495846           (на, строительных, площадках, очистных)    2.0\n2  9495846  (строительных, площадках, очистных, сооружениях)    2.0\n3  9495850                   (гнутье, арматурной, стали, на)    2.0\n4  9495850             (арматурной, стали, на, механических)    2.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>responsibilities_bigrams</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>9495846</td>\n      <td>(работа, на, строительных, площадках)</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>9495846</td>\n      <td>(на, строительных, площадках, очистных)</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>9495846</td>\n      <td>(строительных, площадках, очистных, сооружениях)</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9495850</td>\n      <td>(гнутье, арматурной, стали, на)</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>9495850</td>\n      <td>(арматурной, стали, на, механических)</td>\n      <td>2.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(DATA_PATH)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vacancies = df['id'].unique()\n",
    "df.index = df['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "results = pd.DataFrame()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegression(random_state=RANDOM_STATE) + CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "Train shape: (61297, 3), test shape: (19220, 3)\n",
      "========================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.68      0.72      2644\n",
      "         1.0       0.74      0.89      0.81      7523\n",
      "         2.0       0.85      0.73      0.78      9053\n",
      "\n",
      "    accuracy                           0.79     19220\n",
      "   macro avg       0.78      0.77      0.77     19220\n",
      "weighted avg       0.79      0.79      0.79     19220\n",
      "\n",
      "========================================\n",
      "Fold 1:\n",
      "Train shape: (62564, 3), test shape: (17953, 3)\n",
      "========================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.58      0.66      3135\n",
      "         1.0       0.82      0.84      0.83      8223\n",
      "         2.0       0.73      0.79      0.76      6595\n",
      "\n",
      "    accuracy                           0.77     17953\n",
      "   macro avg       0.77      0.74      0.75     17953\n",
      "weighted avg       0.77      0.77      0.77     17953\n",
      "\n",
      "========================================\n",
      "Fold 2:\n",
      "Train shape: (62016, 3), test shape: (18501, 3)\n",
      "========================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.69      0.70      2766\n",
      "         1.0       0.82      0.91      0.86      7902\n",
      "         2.0       0.86      0.78      0.82      7833\n",
      "\n",
      "    accuracy                           0.82     18501\n",
      "   macro avg       0.80      0.79      0.79     18501\n",
      "weighted avg       0.82      0.82      0.82     18501\n",
      "\n",
      "========================================\n",
      "Fold 3:\n",
      "Train shape: (66801, 3), test shape: (13716, 3)\n",
      "========================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.64      0.67      0.65      1774\n",
      "         1.0       0.80      0.85      0.82      5843\n",
      "         2.0       0.80      0.74      0.77      6099\n",
      "\n",
      "    accuracy                           0.78     13716\n",
      "   macro avg       0.75      0.75      0.75     13716\n",
      "weighted avg       0.78      0.78      0.78     13716\n",
      "\n",
      "========================================\n",
      "Fold 4:\n",
      "Train shape: (69390, 3), test shape: (11127, 3)\n",
      "========================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.64      0.51      0.57      2134\n",
      "         1.0       0.78      0.71      0.75      4577\n",
      "         2.0       0.64      0.75      0.69      4416\n",
      "\n",
      "    accuracy                           0.69     11127\n",
      "   macro avg       0.68      0.66      0.67     11127\n",
      "weighted avg       0.70      0.69      0.69     11127\n",
      "\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "kfold_results_acc = []\n",
    "kfold_results_f1 = []\n",
    "for i, (train_index, test_index) in enumerate(kf.split(vacancies)):\n",
    "    print(f\"Fold {i}:\")\n",
    "    \n",
    "    train = df.loc[vacancies[train_index]]\n",
    "    test = df.loc[vacancies[test_index]]\n",
    "    print(f'Train shape: {train.shape}, test shape: {test.shape}')\n",
    "\n",
    "    count_vect = CountVectorizer(preprocessor=lambda x:x,\n",
    "                                 tokenizer=lambda x:x)\n",
    "    X_train = count_vect.fit_transform(doc[:-1] for doc in train['responsibilities_bigrams'])\n",
    "\n",
    "    lr = LogisticRegression(random_state=RANDOM_STATE)\n",
    "    lr.fit(X_train, train['class'])\n",
    "\n",
    "    X_test = count_vect.transform(test['responsibilities_bigrams'])\n",
    "    pred = lr.predict(X_test)\n",
    "    kfold_results_acc.append(balanced_accuracy_score(test['class'], pred))\n",
    "    kfold_results_f1.append(f1_score(test['class'], pred, average='weighted'))\n",
    "    print('==' * 20)\n",
    "    print(classification_report(test['class'], pred))\n",
    "    print('==' * 20)\n",
    "\n",
    "mdl = f'LogisticRegression(random_state={RANDOM_STATE})'\n",
    "results.loc['balanced_accuracy_score', mdl] = np.mean(kfold_results_acc)\n",
    "results.loc['f1_score', mdl] = np.mean(kfold_results_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# LogisticRegression(random_state=RANDOM_STATE, max_iter=500, n_jobs=-1) + CountVectorizer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "Train shape: (61297, 3), test shape: (19220, 3)\n",
      "========================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.68      0.72      2644\n",
      "         1.0       0.74      0.90      0.81      7523\n",
      "         2.0       0.85      0.73      0.78      9053\n",
      "\n",
      "    accuracy                           0.79     19220\n",
      "   macro avg       0.79      0.77      0.77     19220\n",
      "weighted avg       0.80      0.79      0.79     19220\n",
      "\n",
      "========================================\n",
      "Fold 1:\n",
      "Train shape: (62564, 3), test shape: (17953, 3)\n",
      "========================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.58      0.65      3135\n",
      "         1.0       0.81      0.83      0.82      8223\n",
      "         2.0       0.73      0.79      0.76      6595\n",
      "\n",
      "    accuracy                           0.77     17953\n",
      "   macro avg       0.76      0.73      0.75     17953\n",
      "weighted avg       0.77      0.77      0.77     17953\n",
      "\n",
      "========================================\n",
      "Fold 2:\n",
      "Train shape: (62016, 3), test shape: (18501, 3)\n",
      "========================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.69      0.71      2766\n",
      "         1.0       0.82      0.91      0.86      7902\n",
      "         2.0       0.86      0.78      0.82      7833\n",
      "\n",
      "    accuracy                           0.82     18501\n",
      "   macro avg       0.80      0.79      0.80     18501\n",
      "weighted avg       0.82      0.82      0.82     18501\n",
      "\n",
      "========================================\n",
      "Fold 3:\n",
      "Train shape: (66801, 3), test shape: (13716, 3)\n",
      "========================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.63      0.67      0.65      1774\n",
      "         1.0       0.80      0.85      0.82      5843\n",
      "         2.0       0.80      0.74      0.77      6099\n",
      "\n",
      "    accuracy                           0.78     13716\n",
      "   macro avg       0.75      0.75      0.75     13716\n",
      "weighted avg       0.78      0.78      0.78     13716\n",
      "\n",
      "========================================\n",
      "Fold 4:\n",
      "Train shape: (69390, 3), test shape: (11127, 3)\n",
      "========================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.63      0.51      0.57      2134\n",
      "         1.0       0.78      0.71      0.75      4577\n",
      "         2.0       0.64      0.75      0.69      4416\n",
      "\n",
      "    accuracy                           0.69     11127\n",
      "   macro avg       0.68      0.66      0.67     11127\n",
      "weighted avg       0.70      0.69      0.69     11127\n",
      "\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "kfold_results_acc = []\n",
    "kfold_results_f1 = []\n",
    "for i, (train_index, test_index) in enumerate(kf.split(vacancies)):\n",
    "    print(f\"Fold {i}:\")\n",
    "    \n",
    "    train = df.loc[vacancies[train_index]]\n",
    "    test = df.loc[vacancies[test_index]]\n",
    "    print(f'Train shape: {train.shape}, test shape: {test.shape}')\n",
    "\n",
    "    count_vect = CountVectorizer(preprocessor=lambda x:x,\n",
    "                                 tokenizer=lambda x:x)\n",
    "    X_train = count_vect.fit_transform(doc[:-1] for doc in train['responsibilities_bigrams'])\n",
    "\n",
    "    lr = LogisticRegression(random_state=RANDOM_STATE, max_iter=500, n_jobs=-1)\n",
    "    lr.fit(X_train, train['class'])\n",
    "\n",
    "    X_test = count_vect.transform(test['responsibilities_bigrams'])\n",
    "    pred = lr.predict(X_test)\n",
    "    kfold_results_acc.append(balanced_accuracy_score(test['class'], pred))\n",
    "    kfold_results_f1.append(f1_score(test['class'], pred, average='weighted'))\n",
    "    print('==' * 20)\n",
    "    print(classification_report(test['class'], pred))\n",
    "    print('==' * 20)\n",
    "\n",
    "mdl = f'LogisticRegression(random_state={RANDOM_STATE}, max_iter=500)'\n",
    "results.loc['balanced_accuracy_score', mdl] = np.mean(kfold_results_acc)\n",
    "results.loc['f1_score', mdl] = np.mean(kfold_results_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# LinearSVC(random_state=RANDOM_STATE) + CountVectorizer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "Train shape: (61297, 3), test shape: (19220, 3)\n",
      "========================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.69      0.71      2644\n",
      "         1.0       0.73      0.89      0.80      7523\n",
      "         2.0       0.84      0.71      0.77      9053\n",
      "\n",
      "    accuracy                           0.78     19220\n",
      "   macro avg       0.77      0.76      0.76     19220\n",
      "weighted avg       0.79      0.78      0.78     19220\n",
      "\n",
      "========================================\n",
      "Fold 1:\n",
      "Train shape: (62564, 3), test shape: (17953, 3)\n",
      "========================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.59      0.65      3135\n",
      "         1.0       0.81      0.83      0.82      8223\n",
      "         2.0       0.74      0.77      0.76      6595\n",
      "\n",
      "    accuracy                           0.77     17953\n",
      "   macro avg       0.75      0.73      0.74     17953\n",
      "weighted avg       0.77      0.77      0.77     17953\n",
      "\n",
      "========================================\n",
      "Fold 2:\n",
      "Train shape: (62016, 3), test shape: (18501, 3)\n",
      "========================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.69      0.70      2766\n",
      "         1.0       0.82      0.91      0.86      7902\n",
      "         2.0       0.86      0.77      0.81      7833\n",
      "\n",
      "    accuracy                           0.82     18501\n",
      "   macro avg       0.79      0.79      0.79     18501\n",
      "weighted avg       0.82      0.82      0.82     18501\n",
      "\n",
      "========================================\n",
      "Fold 3:\n",
      "Train shape: (66801, 3), test shape: (13716, 3)\n",
      "========================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      0.67      0.64      1774\n",
      "         1.0       0.79      0.85      0.82      5843\n",
      "         2.0       0.80      0.73      0.76      6099\n",
      "\n",
      "    accuracy                           0.77     13716\n",
      "   macro avg       0.74      0.75      0.74     13716\n",
      "weighted avg       0.77      0.77      0.77     13716\n",
      "\n",
      "========================================\n",
      "Fold 4:\n",
      "Train shape: (69390, 3), test shape: (11127, 3)\n",
      "========================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.54      0.56      2134\n",
      "         1.0       0.77      0.71      0.74      4577\n",
      "         2.0       0.64      0.72      0.68      4416\n",
      "\n",
      "    accuracy                           0.68     11127\n",
      "   macro avg       0.67      0.66      0.66     11127\n",
      "weighted avg       0.68      0.68      0.68     11127\n",
      "\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "kfold_results_acc = []\n",
    "kfold_results_f1 = []\n",
    "for i, (train_index, test_index) in enumerate(kf.split(vacancies)):\n",
    "    print(f\"Fold {i}:\")\n",
    "    \n",
    "    train = df.loc[vacancies[train_index]]\n",
    "    test = df.loc[vacancies[test_index]]\n",
    "    print(f'Train shape: {train.shape}, test shape: {test.shape}')\n",
    "\n",
    "    count_vect = CountVectorizer(preprocessor=lambda x:x,\n",
    "                                 tokenizer=lambda x:x)\n",
    "    X_train = count_vect.fit_transform(doc[:-1] for doc in train['responsibilities_bigrams'])\n",
    "\n",
    "    lr = LinearSVC(random_state=RANDOM_STATE)\n",
    "    lr.fit(X_train, train['class'])\n",
    "\n",
    "    X_test = count_vect.transform(test['responsibilities_bigrams'])\n",
    "    pred = lr.predict(X_test)\n",
    "    kfold_results_acc.append(balanced_accuracy_score(test['class'], pred))\n",
    "    kfold_results_f1.append(f1_score(test['class'], pred, average='weighted'))\n",
    "    print('==' * 20)\n",
    "    print(classification_report(test['class'], pred))\n",
    "    print('==' * 20)\n",
    "\n",
    "mdl = f'LinearSVC(random_state={RANDOM_STATE})'\n",
    "results.loc['balanced_accuracy_score', mdl] = np.mean(kfold_results_acc)\n",
    "results.loc['f1_score', mdl] = np.mean(kfold_results_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# LogisticRegression(random_state=RANDOM_STATE, max_iter=500, n_jobs=-1) + TfidfVectorizer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "Train shape: (61297, 3), test shape: (19220, 3)\n",
      "========================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.65      0.72      2644\n",
      "         1.0       0.75      0.89      0.82      7523\n",
      "         2.0       0.84      0.75      0.79      9053\n",
      "\n",
      "    accuracy                           0.79     19220\n",
      "   macro avg       0.80      0.77      0.78     19220\n",
      "weighted avg       0.80      0.79      0.79     19220\n",
      "\n",
      "========================================\n",
      "Fold 1:\n",
      "Train shape: (62564, 3), test shape: (17953, 3)\n",
      "========================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.55      0.65      3135\n",
      "         1.0       0.82      0.83      0.83      8223\n",
      "         2.0       0.72      0.81      0.76      6595\n",
      "\n",
      "    accuracy                           0.77     17953\n",
      "   macro avg       0.78      0.73      0.75     17953\n",
      "weighted avg       0.78      0.77      0.77     17953\n",
      "\n",
      "========================================\n",
      "Fold 2:\n",
      "Train shape: (62016, 3), test shape: (18501, 3)\n",
      "========================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.65      0.70      2766\n",
      "         1.0       0.82      0.90      0.86      7902\n",
      "         2.0       0.84      0.80      0.82      7833\n",
      "\n",
      "    accuracy                           0.82     18501\n",
      "   macro avg       0.81      0.79      0.79     18501\n",
      "weighted avg       0.82      0.82      0.82     18501\n",
      "\n",
      "========================================\n",
      "Fold 3:\n",
      "Train shape: (66801, 3), test shape: (13716, 3)\n",
      "========================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.65      0.66      1774\n",
      "         1.0       0.81      0.85      0.83      5843\n",
      "         2.0       0.79      0.76      0.78      6099\n",
      "\n",
      "    accuracy                           0.78     13716\n",
      "   macro avg       0.76      0.75      0.75     13716\n",
      "weighted avg       0.78      0.78      0.78     13716\n",
      "\n",
      "========================================\n",
      "Fold 4:\n",
      "Train shape: (69390, 3), test shape: (11127, 3)\n",
      "========================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.66      0.50      0.57      2134\n",
      "         1.0       0.78      0.71      0.74      4577\n",
      "         2.0       0.64      0.77      0.70      4416\n",
      "\n",
      "    accuracy                           0.69     11127\n",
      "   macro avg       0.69      0.66      0.67     11127\n",
      "weighted avg       0.70      0.69      0.69     11127\n",
      "\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "kfold_results_acc = []\n",
    "kfold_results_f1 = []\n",
    "for i, (train_index, test_index) in enumerate(kf.split(vacancies)):\n",
    "    print(f\"Fold {i}:\")\n",
    "    \n",
    "    train = df.loc[vacancies[train_index]]\n",
    "    test = df.loc[vacancies[test_index]]\n",
    "    print(f'Train shape: {train.shape}, test shape: {test.shape}')\n",
    "\n",
    "    vect = TfidfVectorizer(preprocessor=lambda x:x,\n",
    "                                 tokenizer=lambda x:x)\n",
    "    X_train = vect.fit_transform(doc[:-1] for doc in train['responsibilities_bigrams'])\n",
    "\n",
    "    lr = LogisticRegression(random_state=RANDOM_STATE, max_iter=500, n_jobs=-1)\n",
    "    lr.fit(X_train, train['class'])\n",
    "\n",
    "    X_test = vect.transform(test['responsibilities_bigrams'])\n",
    "    pred = lr.predict(X_test)\n",
    "    kfold_results_acc.append(balanced_accuracy_score(test['class'], pred))\n",
    "    kfold_results_f1.append(f1_score(test['class'], pred, average='weighted'))\n",
    "    print('==' * 20)\n",
    "    print(classification_report(test['class'], pred))\n",
    "    print('==' * 20)\n",
    "\n",
    "mdl = f'LogisticRegression(random_state={RANDOM_STATE}, max_iter=500) + TFIDF'\n",
    "results.loc['balanced_accuracy_score', mdl] = np.mean(kfold_results_acc)\n",
    "results.loc['f1_score', mdl] = np.mean(kfold_results_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# LinearSVC(random_state=RANDOM_STATE, C=0.2) + CountVectorizer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "Train shape: (61297, 3), test shape: (19220, 3)\n",
      "========================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.68      0.72      2644\n",
      "         1.0       0.74      0.90      0.81      7523\n",
      "         2.0       0.85      0.73      0.78      9053\n",
      "\n",
      "    accuracy                           0.79     19220\n",
      "   macro avg       0.78      0.77      0.77     19220\n",
      "weighted avg       0.79      0.79      0.78     19220\n",
      "\n",
      "========================================\n",
      "Fold 1:\n",
      "Train shape: (62564, 3), test shape: (17953, 3)\n",
      "========================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.59      0.66      3135\n",
      "         1.0       0.81      0.83      0.82      8223\n",
      "         2.0       0.73      0.79      0.76      6595\n",
      "\n",
      "    accuracy                           0.77     17953\n",
      "   macro avg       0.77      0.74      0.75     17953\n",
      "weighted avg       0.77      0.77      0.77     17953\n",
      "\n",
      "========================================\n",
      "Fold 2:\n",
      "Train shape: (62016, 3), test shape: (18501, 3)\n",
      "========================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.68      0.70      2766\n",
      "         1.0       0.82      0.91      0.86      7902\n",
      "         2.0       0.86      0.79      0.82      7833\n",
      "\n",
      "    accuracy                           0.82     18501\n",
      "   macro avg       0.80      0.79      0.79     18501\n",
      "weighted avg       0.82      0.82      0.82     18501\n",
      "\n",
      "========================================\n",
      "Fold 3:\n",
      "Train shape: (66801, 3), test shape: (13716, 3)\n",
      "========================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.64      0.67      0.65      1774\n",
      "         1.0       0.80      0.85      0.82      5843\n",
      "         2.0       0.80      0.74      0.77      6099\n",
      "\n",
      "    accuracy                           0.78     13716\n",
      "   macro avg       0.75      0.75      0.75     13716\n",
      "weighted avg       0.78      0.78      0.78     13716\n",
      "\n",
      "========================================\n",
      "Fold 4:\n",
      "Train shape: (69390, 3), test shape: (11127, 3)\n",
      "========================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.62      0.53      0.57      2134\n",
      "         1.0       0.78      0.72      0.75      4577\n",
      "         2.0       0.65      0.74      0.69      4416\n",
      "\n",
      "    accuracy                           0.69     11127\n",
      "   macro avg       0.68      0.66      0.67     11127\n",
      "weighted avg       0.70      0.69      0.69     11127\n",
      "\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "kfold_results_acc = []\n",
    "kfold_results_f1 = []\n",
    "for i, (train_index, test_index) in enumerate(kf.split(vacancies)):\n",
    "    print(f\"Fold {i}:\")\n",
    "    \n",
    "    train = df.loc[vacancies[train_index]]\n",
    "    test = df.loc[vacancies[test_index]]\n",
    "    print(f'Train shape: {train.shape}, test shape: {test.shape}')\n",
    "\n",
    "    count_vect = CountVectorizer(preprocessor=lambda x:x,\n",
    "                                 tokenizer=lambda x:x)\n",
    "    X_train = count_vect.fit_transform(doc[:-1] for doc in train['responsibilities_bigrams'])\n",
    "\n",
    "    lr = LinearSVC(random_state=RANDOM_STATE, C=0.2)\n",
    "    lr.fit(X_train, train['class'])\n",
    "\n",
    "    X_test = count_vect.transform(test['responsibilities_bigrams'])\n",
    "    pred = lr.predict(X_test)\n",
    "    kfold_results_acc.append(balanced_accuracy_score(test['class'], pred))\n",
    "    kfold_results_f1.append(f1_score(test['class'], pred, average='weighted'))\n",
    "    print('==' * 20)\n",
    "    print(classification_report(test['class'], pred))\n",
    "    print('==' * 20)\n",
    "\n",
    "mdl = f'LinearSVC(random_state={RANDOM_STATE}, C=0.2)'\n",
    "results.loc['balanced_accuracy_score', mdl] = np.mean(kfold_results_acc)\n",
    "results.loc['f1_score', mdl] = np.mean(kfold_results_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# LogisticRegression(random_state=RANDOM_STATE, max_iter=500, n_jobs=-1, class_weight={0: 1.2, 1: 1.1, 2: 0.7}) + TfidfVectorizer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "Train shape: (61297, 3), test shape: (19220, 3)\n",
      "========================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.69      0.72      2644\n",
      "         1.0       0.72      0.92      0.81      7523\n",
      "         2.0       0.86      0.69      0.77      9053\n",
      "\n",
      "    accuracy                           0.78     19220\n",
      "   macro avg       0.78      0.77      0.77     19220\n",
      "weighted avg       0.79      0.78      0.78     19220\n",
      "\n",
      "========================================\n",
      "Fold 1:\n",
      "Train shape: (62564, 3), test shape: (17953, 3)\n",
      "========================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.60      0.66      3135\n",
      "         1.0       0.80      0.86      0.83      8223\n",
      "         2.0       0.76      0.76      0.76      6595\n",
      "\n",
      "    accuracy                           0.78     17953\n",
      "   macro avg       0.76      0.74      0.75     17953\n",
      "weighted avg       0.77      0.78      0.77     17953\n",
      "\n",
      "========================================\n",
      "Fold 2:\n",
      "Train shape: (62016, 3), test shape: (18501, 3)\n",
      "========================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.70      0.70      2766\n",
      "         1.0       0.80      0.93      0.86      7902\n",
      "         2.0       0.88      0.74      0.81      7833\n",
      "\n",
      "    accuracy                           0.81     18501\n",
      "   macro avg       0.80      0.79      0.79     18501\n",
      "weighted avg       0.82      0.81      0.81     18501\n",
      "\n",
      "========================================\n",
      "Fold 3:\n",
      "Train shape: (66801, 3), test shape: (13716, 3)\n",
      "========================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.62      0.69      0.65      1774\n",
      "         1.0       0.78      0.88      0.83      5843\n",
      "         2.0       0.83      0.70      0.76      6099\n",
      "\n",
      "    accuracy                           0.77     13716\n",
      "   macro avg       0.74      0.76      0.75     13716\n",
      "weighted avg       0.78      0.77      0.77     13716\n",
      "\n",
      "========================================\n",
      "Fold 4:\n",
      "Train shape: (69390, 3), test shape: (11127, 3)\n",
      "========================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      0.55      0.58      2134\n",
      "         1.0       0.75      0.75      0.75      4577\n",
      "         2.0       0.67      0.70      0.68      4416\n",
      "\n",
      "    accuracy                           0.69     11127\n",
      "   macro avg       0.68      0.67      0.67     11127\n",
      "weighted avg       0.69      0.69      0.69     11127\n",
      "\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "kfold_results_acc = []\n",
    "kfold_results_f1 = []\n",
    "for i, (train_index, test_index) in enumerate(kf.split(vacancies)):\n",
    "    print(f\"Fold {i}:\")\n",
    "    \n",
    "    train = df.loc[vacancies[train_index]]\n",
    "    test = df.loc[vacancies[test_index]]\n",
    "    print(f'Train shape: {train.shape}, test shape: {test.shape}')\n",
    "\n",
    "    vect = TfidfVectorizer(preprocessor=lambda x:x,\n",
    "                                 tokenizer=lambda x:x)\n",
    "    X_train = vect.fit_transform(doc[:-1] for doc in train['responsibilities_bigrams'])\n",
    "\n",
    "    lr = LogisticRegression(random_state=RANDOM_STATE, max_iter=500, n_jobs=-1, class_weight={0: 1.2, 1: 1.1, 2: 0.7})\n",
    "    lr.fit(X_train, train['class'])\n",
    "\n",
    "    X_test = vect.transform(test['responsibilities_bigrams'])\n",
    "    pred = lr.predict(X_test)\n",
    "    kfold_results_acc.append(balanced_accuracy_score(test['class'], pred))\n",
    "    kfold_results_f1.append(f1_score(test['class'], pred, average='weighted'))\n",
    "    print('==' * 20)\n",
    "    print(classification_report(test['class'], pred))\n",
    "    print('==' * 20)\n",
    "\n",
    "mdl = f'LogisticRegression(random_state={RANDOM_STATE}, max_iter=500) + TFIDF + weights'\n",
    "results.loc['balanced_accuracy_score', mdl] = np.mean(kfold_results_acc)\n",
    "results.loc['f1_score', mdl] = np.mean(kfold_results_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Сравнение результатов"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "                         LogisticRegression(random_state=42)  \\\nbalanced_accuracy_score                             0.741544   \nf1_score                                            0.768846   \n\n                         LogisticRegression(random_state=42, max_iter=500)  \\\nbalanced_accuracy_score                                           0.742183   \nf1_score                                                          0.769099   \n\n                         LinearSVC(random_state=42)  \\\nbalanced_accuracy_score                    0.737799   \nf1_score                                   0.761824   \n\n                         LogisticRegression(random_state=42, max_iter=500) + TFIDF  \\\nbalanced_accuracy_score                                           0.738890           \nf1_score                                                          0.771397           \n\n                         LinearSVC(random_state=42, C=0.2)  \\\nbalanced_accuracy_score                           0.742187   \nf1_score                                          0.769039   \n\n                         LogisticRegression(random_state=42, max_iter=500) + TFIDF + weights  \nbalanced_accuracy_score                                           0.743609                    \nf1_score                                                          0.765898                    ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>LogisticRegression(random_state=42)</th>\n      <th>LogisticRegression(random_state=42, max_iter=500)</th>\n      <th>LinearSVC(random_state=42)</th>\n      <th>LogisticRegression(random_state=42, max_iter=500) + TFIDF</th>\n      <th>LinearSVC(random_state=42, C=0.2)</th>\n      <th>LogisticRegression(random_state=42, max_iter=500) + TFIDF + weights</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>balanced_accuracy_score</th>\n      <td>0.741544</td>\n      <td>0.742183</td>\n      <td>0.737799</td>\n      <td>0.738890</td>\n      <td>0.742187</td>\n      <td>0.743609</td>\n    </tr>\n    <tr>\n      <th>f1_score</th>\n      <td>0.768846</td>\n      <td>0.769099</td>\n      <td>0.761824</td>\n      <td>0.771397</td>\n      <td>0.769039</td>\n      <td>0.765898</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "В результате выбрана лучшая модель - LogisticRegression(random_state=RANDOM_STATE, max_iter=500, n_jobs=-1) + TfidfVectorizer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}